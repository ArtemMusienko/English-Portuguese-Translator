{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Решение задачи:"
      ],
      "metadata": {
        "id": "sxzOyBmtxFos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импортируем необходимые библиотеки:"
      ],
      "metadata": {
        "id": "veB-vLcyxH_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from random import randint\n",
        "import pandas as pd\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Dense, Embedding, LSTM, Input\n",
        "from keras.optimizers import RMSprop, Adadelta, Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict, Counter"
      ],
      "metadata": {
        "id": "XDvjWgUvxIWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним скачивание архива с словарём для **англо-португальского** перевода. Архив я скачал с https://www.manythings.org/anki/ и поместил его в **Google Диск**:"
      ],
      "metadata": {
        "id": "u36_WwbHIZw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \"https://docs.google.com/uc?export=download&id=1p14kuZUHZw229qT0bSWO8qDKxo3xQ5t6\" -O por-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5OQP7VbIZ9V",
        "outputId": "4956f796-80d3-4676-eb3a-00db563e577e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-08-30 09:40:03--  https://docs.google.com/uc?export=download&id=1p14kuZUHZw229qT0bSWO8qDKxo3xQ5t6\n",
            "Resolving docs.google.com (docs.google.com)... 142.250.4.139, 142.250.4.101, 142.250.4.102, ...\n",
            "Connecting to docs.google.com (docs.google.com)|142.250.4.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1p14kuZUHZw229qT0bSWO8qDKxo3xQ5t6&export=download [following]\n",
            "--2025-08-30 09:40:04--  https://drive.usercontent.google.com/download?id=1p14kuZUHZw229qT0bSWO8qDKxo3xQ5t6&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.10.132, 2404:6800:4003:c0f::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.10.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6602160 (6.3M) [application/octet-stream]\n",
            "Saving to: ‘por-eng.zip’\n",
            "\n",
            "por-eng.zip         100%[===================>]   6.30M  17.5MB/s    in 0.4s    \n",
            "\n",
            "2025-08-30 09:40:08 (17.5 MB/s) - ‘por-eng.zip’ saved [6602160/6602160]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Распакуем архив:"
      ],
      "metadata": {
        "id": "KVvu5JFAIcRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o por-eng.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiWCO72PIcbo",
        "outputId": "dbf47e65-6d9a-4479-812f-66ca13848fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  por-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: por.txt                 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Определение констант в начале программы - это хорошая практика при разработке вашего программного обеспечения. Вы всегда быстро сможете изменить параметры обучения, а не вносить изменения по всему коду. Особенно, если обучение происходит на ограниченных ресурсах, то без подбора параметров вам не обойтись!  "
      ],
      "metadata": {
        "id": "8Y1Vl3dmId7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 256 # размер обучающего пакета\n",
        "EPOCHS = 25 # число эпох обучения\n",
        "LATENT_DIM = 256 # размерность латентного или контексного вектора\n",
        "NUM_SAMPLES = 50000 # число примеров для обучения\n",
        "FILE_NAME = \"por.txt\" # имя файла со словарем в архиве\n",
        "SOS = '<start>' # токен начала последовательсти\n",
        "EOS = '<end>' # токен окончания последовательсти"
      ],
      "metadata": {
        "id": "8WZ6Is96IeHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Byte Pair Encoding (BPE)** — это алгоритм токенизации, который используется для разбиения текста на подслова (**subwords**), что особенно полезно для обработки редких слов и языков с богатой морфологией.\n",
        "\n",
        "Метод `__init__` инициализирует объект BPE с параметрами для обучения. Метод `train` обучает **BPE**, создавая словарь токенов путем итеративного объединения наиболее частых пар. Метод `update_splits` обновляет разбиения слов (`self.splits`), заменяя указанную пару токенов (`lhs`, `rhs`) на их объединение. Метод `get_pairs_freq` вычисляет частотность всех пар соседних токенов в текущих разбиениях слов. Метод `tokenize` токенизирует входной текст, используя обученные объединения (`self.merges`)."
      ],
      "metadata": {
        "id": "NzzkhHZ3T-Zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BPE:\n",
        "    def __init__(\n",
        "        self,\n",
        "        corpus: list[str],  # Корпус текстов для обучения токенизатора\n",
        "        vocab_size: int,    # Желаемый размер словаря (количество токенов)\n",
        "        max_iter: int | None = None,  # Максимальное количество итераций объединения\n",
        "        debug: bool = False,  # Флаг для вывода отладочной информации\n",
        "    ):\n",
        "        # Сохраняем входные параметры\n",
        "        self.corpus = corpus  # Список текстов (предложений) для обучения\n",
        "        self.vocab_size = vocab_size  # Целевой размер словаря\n",
        "        self.vocab = []  # Список токенов в словаре (начинается с символов, затем добавляются подслова)\n",
        "        self.word_freq = Counter()  # Словарь для хранения частотности слов\n",
        "        self.splits = {}  # Словарь вида {слово: [токены]}, например, {'highest': ['high', 'est</w>']}\n",
        "        self.merges = {}  # Словарь объединений пар, например, {('high', 'est</w>'): 'highest'}\n",
        "        self.max_iter = max_iter  # Ограничение на число итераций\n",
        "        self.debug = debug  # Флаг для отладки\n",
        "        self.special_tokens = ['<start>', '<end>']  # Специальные токены для начала и конца последовательности\n",
        "\n",
        "    def train(self):\n",
        "        # Подсчет частотности слов в корпусе\n",
        "        for document in self.corpus:\n",
        "            # Разбиваем каждое предложение на слова\n",
        "            words = document.split()\n",
        "            # Обновляем счетчик частотности слов\n",
        "            self.word_freq += Counter(words)\n",
        "\n",
        "        # Инициализация словаря и разбиений\n",
        "        # Создаем начальный алфавит из всех уникальных символов в словах\n",
        "        alphabet = set()\n",
        "        for word in self.word_freq:\n",
        "            alphabet |= set(list(word))  # Добавляем символы слова в множество\n",
        "        alphabet.add(\"</w>\")  # Добавляем токен конца слова\n",
        "        alphabet |= set(self.special_tokens)  # Добавляем специальные токены\n",
        "        self.vocab = list(alphabet)  # Преобразуем множество в отсортированный список\n",
        "        self.vocab.sort()\n",
        "\n",
        "        # Инициализируем разбиения слов (splits)\n",
        "        for word in self.word_freq:\n",
        "            if word in self.special_tokens:\n",
        "                # Специальные токены остаются как есть\n",
        "                self.splits[word] = [word]\n",
        "            else:\n",
        "                # Обычные слова разбиваем на символы и добавляем </w>\n",
        "                self.splits[word] = list(word) + [\"</w>\"]\n",
        "\n",
        "        # Выводим начальные разбиения для отладки, если debug=True\n",
        "        if self.debug:\n",
        "            print(f\"Начальные разбиения: {self.splits}\")\n",
        "\n",
        "        # Счетчик итераций\n",
        "        cnt = 0\n",
        "        # Продолжаем, пока словарь не достигнет заданного размера\n",
        "        while len(self.vocab) < self.vocab_size:\n",
        "            # Проверяем ограничение на число итераций\n",
        "            if self.max_iter and cnt >= self.max_iter:\n",
        "                break\n",
        "\n",
        "            # Находим частотность всех пар токенов\n",
        "            pair_freq = self.get_pairs_freq()\n",
        "\n",
        "            # Если пар больше нет, прерываем обучение\n",
        "            if len(pair_freq) == 0:\n",
        "                print(\"Нет доступных пар для объединения\")\n",
        "                break\n",
        "\n",
        "            # Выбираем наиболее частую пару\n",
        "            pair = max(pair_freq, key=pair_freq.get)\n",
        "\n",
        "            # Обновляем разбиения слов, заменяя выбранную пару на объединенный токен\n",
        "            self.update_splits(pair[0], pair[1])\n",
        "\n",
        "            # Выводим обновленные разбиения для отладки\n",
        "            if self.debug:\n",
        "                print(f\"Обновленные разбиения: {self.splits}\")\n",
        "\n",
        "            # Сохраняем объединение пары\n",
        "            self.merges[pair] = pair[0] + pair[1]\n",
        "\n",
        "            # Добавляем новый токен в словарь\n",
        "            self.vocab.append(pair[0] + pair[1])\n",
        "\n",
        "            # Выводим информацию о текущей паре и размере словаря для отладки\n",
        "            if self.debug:\n",
        "                print(\n",
        "                    f\"Наиболее частая пара ({max(pair_freq.values())} раз): \"\n",
        "                    f\"{pair[0]}, {pair[1]}. Размер словаря: {len(self.vocab)}\"\n",
        "                )\n",
        "\n",
        "            cnt += 1\n",
        "\n",
        "    def update_splits(self, lhs: str, rhs: str):\n",
        "        for word, word_split in self.splits.items():\n",
        "            new_split = []\n",
        "            cursor = 0\n",
        "            # Проходим по токенам слова\n",
        "            while cursor < len(word_split):\n",
        "                # Если найдена пара (lhs, rhs), объединяем её\n",
        "                if (\n",
        "                    word_split[cursor] == lhs\n",
        "                    and cursor + 1 < len(word_split)\n",
        "                    and word_split[cursor + 1] == rhs\n",
        "                ):\n",
        "                    new_split.append(lhs + rhs)  # Добавляем объединенный токен\n",
        "                    cursor += 2  # Пропускаем оба токена пары\n",
        "                else:\n",
        "                    new_split.append(word_split[cursor])  # Добавляем текущий токен\n",
        "                    cursor += 1\n",
        "            # Обновляем разбиение для слова\n",
        "            self.splits[word] = new_split\n",
        "\n",
        "    def get_pairs_freq(self) -> dict:\n",
        "        pairs_freq = defaultdict(int)\n",
        "        for word, freq in self.word_freq.items():\n",
        "            split = self.splits[word]\n",
        "            # Перебираем соседние токены в разбиении слова\n",
        "            for i in range(len(split)):\n",
        "                if i + 1 < len(split):\n",
        "                    # Увеличиваем частоту пары на частоту слова\n",
        "                    pairs_freq[(split[i], split[i + 1])] += freq\n",
        "\n",
        "        return pairs_freq\n",
        "\n",
        "    def tokenize(self, s: str) -> list[str]:\n",
        "        splits = []\n",
        "        # Разбиваем текст на слова\n",
        "        for t in s.split():\n",
        "            if t in self.special_tokens:\n",
        "                # Специальные токены остаются без изменений\n",
        "                splits.append([t])\n",
        "            else:\n",
        "                # Обычные слова разбиваем на символы и добавляем </w>\n",
        "                splits.append(list(t) + [\"</w>\"])\n",
        "\n",
        "        # Применяем все объединения из merges\n",
        "        for lhs, rhs in self.merges:\n",
        "            for idx, split in enumerate(splits):\n",
        "                new_split = []\n",
        "                cursor = 0\n",
        "                while cursor < len(split):\n",
        "                    # Если найдена пара (lhs, rhs), объединяем её\n",
        "                    if (\n",
        "                        cursor + 1 < len(split)\n",
        "                        and split[cursor] == lhs\n",
        "                        and split[cursor + 1] == rhs\n",
        "                    ):\n",
        "                        new_split.append(lhs + rhs)  # Добавляем объединенный токен\n",
        "                        cursor += 2\n",
        "                    else:\n",
        "                        new_split.append(split[cursor])  # Добавляем текущий токен\n",
        "                        cursor += 1\n",
        "                # Проверяем, что объединение не изменило слово\n",
        "                assert \"\".join(new_split) == \"\".join(split)\n",
        "                splits[idx] = new_split\n",
        "\n",
        "        # Объединяем все разбиения в один список токенов\n",
        "        return sum(splits, [])"
      ],
      "metadata": {
        "id": "7e4FY8WzT-oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `texts_to_sequences` преобразует список текстов (**texts**) в список последовательностей индексов, используя **BPE-токенизацию**. Для каждого текста она вызывает метод `bpe.tokenize` для разбиения на токены (**подслова**), а затем использует словарь `word_index` для преобразования каждого токена в соответствующий индекс, заменяя неизвестные токены на **0**.\n",
        "\n",
        "*Результат* — список списков индексов, готовых для подачи в модель машинного обучения."
      ],
      "metadata": {
        "id": "mzPLd9K5WL1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def texts_to_sequences(texts, bpe, word_index):\n",
        "    return [[word_index.get(token, 0) for token in bpe.tokenize(text)] for text in texts]"
      ],
      "metadata": {
        "id": "V3nFcbNXWMBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прежде, чем \"уходить в глубокую разработку\", всегда полезно визуализировать данные, с которыми вам придется работать. В этом нам поможет библиотека **PANDAS**. Несмотря на то, что наш файл текстовый с разделителем \"**табуляция**\", мы всегда можем воспользоваться удобным методом `read_csv`. Данный метод умеет работать с любым текстовым файлом, главное правильно задать ему параметры для парсинга файла. В нашем случае, мы указываем разделитель табуляюцию: `sep='\\t'`."
      ],
      "metadata": {
        "id": "42N53ploIfDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(FILE_NAME, sep='\\t', header=None)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "65cpacWrIfNd",
        "outputId": "9f52e696-e89f-4f6d-b4d6-27493aca7eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0       1                                                  2\n",
              "0   Go.    Vai.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "1   Go.     Vá.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "2   Hi.     Oi.  CC-BY 2.0 (France) Attribution: tatoeba.org #5...\n",
              "3  Run!  Corre!  CC-BY 2.0 (France) Attribution: tatoeba.org #9...\n",
              "4  Run!  Corra!  CC-BY 2.0 (France) Attribution: tatoeba.org #9..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06adf20c-c5b2-4165-870c-e9c8f8423658\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vai.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Go.</td>\n",
              "      <td>Vá.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Oi.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corre!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06adf20c-c5b2-4165-870c-e9c8f8423658')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06adf20c-c5b2-4165-870c-e9c8f8423658 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06adf20c-c5b2-4165-870c-e9c8f8423658');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-16b69492-ad91-4835-ae73-4f58226e4a15\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-16b69492-ad91-4835-ae73-4f58226e4a15')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-16b69492-ad91-4835-ae73-4f58226e4a15 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Часто полезно смотреть на данные не только с \"головы\" (первые записи в выборке), но и с \"хвоста\" (последние записи в выборке):"
      ],
      "metadata": {
        "id": "Sk4HvsqZIgFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[NUM_SAMPLES-5:NUM_SAMPLES]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Ygm8r5wxIgOe",
        "outputId": "597027ba-8314-4adc-cb3d-20832b8b4007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            0                                 1  \\\n",
              "49995  I'm extremely excited.  Eu estou extremamente empolgado.   \n",
              "49996  I'm fairly optimistic.          Estou bastante otimista.   \n",
              "49997  I'm fairly optimistic.       Eu estou bastante otimista.   \n",
              "49998  I'm feeling confident.   Eu estou me sentindo confiante.   \n",
              "49999  I'm feeling very good.   Eu estou me sentindo muito bem.   \n",
              "\n",
              "                                                       2  \n",
              "49995  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "49996  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
              "49997  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
              "49998  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
              "49999  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9653e0c-db70-4b66-bf56-6462e0908913\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I'm extremely excited.</td>\n",
              "      <td>Eu estou extremamente empolgado.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>I'm fairly optimistic.</td>\n",
              "      <td>Estou bastante otimista.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I'm fairly optimistic.</td>\n",
              "      <td>Eu estou bastante otimista.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm feeling confident.</td>\n",
              "      <td>Eu estou me sentindo confiante.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>I'm feeling very good.</td>\n",
              "      <td>Eu estou me sentindo muito bem.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9653e0c-db70-4b66-bf56-6462e0908913')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9653e0c-db70-4b66-bf56-6462e0908913 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9653e0c-db70-4b66-bf56-6462e0908913');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-387e909a-30c7-416c-8c09-29037fdf674b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-387e909a-30c7-416c-8c09-29037fdf674b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-387e909a-30c7-416c-8c09-29037fdf674b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[NUM_SAMPLES-5:NUM_SAMPLES]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"I'm fairly optimistic.\",\n          \"I'm feeling very good.\",\n          \"I'm extremely excited.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Estou bastante otimista.\",\n          \"Eu estou me sentindo muito bem.\",\n          \"Eu estou bastante otimista.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"CC-BY 2.0 (France) Attribution: tatoeba.org #4999932 (CK) & #6993858 (Ricardo14)\",\n          \"CC-BY 2.0 (France) Attribution: tatoeba.org #5171715 (CK) & #5178110 (alexmarcelo)\",\n          \"CC-BY 2.0 (France) Attribution: tatoeba.org #4999932 (CK) & #6993859 (Ricardo14)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если бы мы смотрели на данные только с \"головы\", то решили бы, что работаем только со словами, а с \"хвоста\" мы видим сложные и длинные предложения.\n",
        "\n",
        "Также мы видим, что данные состоят из трех столбцов, нас же интересуют только первых два, где первый столбик - входные данные, второй выходные для нашей будущей модели."
      ],
      "metadata": {
        "id": "nrsHA12xYM1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее сформируем обучаюющую выборку из `NUM_SAMPLES` примеров. По аналогии с чат-ботами мы сформируем массивы из входный фраз `questions` (вопросов) и выходных `answers` (ответов), а также определим токены начала последовательности `SOS` и токены окончания последовательности `EOS`:"
      ],
      "metadata": {
        "id": "sZsEkKScIhJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Собираем вопросы и ответы в списки\n",
        "\n",
        "questions = [] # список входных фраз\n",
        "answers = []   # список ответных фраз\n",
        "\n",
        "with open(FILE_NAME, \"r\", encoding=\"utf-8\") as f: # открываем файл в режиме чтения\n",
        "    lines = f.read().split(\"\\n\")                    # считываем весь файл, разделяя на строки\n",
        "\n",
        "for line in lines[: min(NUM_SAMPLES, len(lines) - 1)]:\n",
        "    # Разделяем строку по табам (входные данные, выходные и ненужный столбец)\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "\n",
        "    # В выходные данные для декодера добавляем токены SOS и EOS\n",
        "    target_text = SOS + ' ' + target_text + ' ' + EOS\n",
        "    questions.append(input_text)\n",
        "    answers.append(target_text)\n",
        "\n",
        "print(\"Число примеров:\", len(answers))\n",
        "\n",
        "#  Получим случайный вопрос и ответ\n",
        "random_index = randint(0, len(questions)-1)\n",
        "print(f'Вопрос : {questions[random_index]}') # Пример входной фразы\n",
        "print(f'Ответ : {answers[random_index]}')    # Пример ответной фразы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R84K8ApIhS3",
        "outputId": "27e8082c-b8ee-4214-8434-913c3b6daab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Число примеров: 50000\n",
            "Вопрос : I'll wait here.\n",
            "Ответ : <start> Eu vou esperar aqui. <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разбиваем данные на обучающую и тестовую выборки (80/20):"
      ],
      "metadata": {
        "id": "up-fE5geIiSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions_train, questions_test, answers_train, answers_test = train_test_split(questions, answers, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QotFPggdIibR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код создает и обучает **BPE-токенизатор** для корпуса текстов. Сначала формируется корпус `corpus_for_bpe`, объединяя обучающие вопросы (`questions_train`) и ответы (`answers_train`), из которых удаляются токены <start> и <end> с пробелами. Затем создается объект **BPE** с заданным размером словаря 20,000 и обучается методом `bpe.train()`, который разбивает слова на подслова, итеративно объединяя наиболее частые пары токенов для построения словаря."
      ],
      "metadata": {
        "id": "R17GrqgmIjY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим BPE токенизатор\n",
        "corpus_for_bpe = questions_train + [a.replace(SOS + ' ', '').replace(' ' + EOS, '').strip() for a in answers_train]\n",
        "bpe = BPE(corpus=corpus_for_bpe, vocab_size=20000, debug=False)\n",
        "bpe.train()"
      ],
      "metadata": {
        "id": "Xa731PAPIjiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код создает словари для преобразования токенов в индексы и обратно после обучения **BPE-токенизатора**. `word_index` сопоставляет каждому токену из `bpe.vocab` уникальный индекс (начиная с 1), а `index_to_word` — обратное сопоставление индексов токенам. Далее, `vocabularyItems` сохраняет пары (токен, индекс) как список, а `vocabularySize` вычисляется как размер `word_index` плюс 1 (для нулевого индекса, обозначающего неизвестные токены):"
      ],
      "metadata": {
        "id": "qJFskxLDIkbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем словари после обучения BPE\n",
        "word_index = {token: i+1 for i, token in enumerate(bpe.vocab)}\n",
        "index_to_word = {i: token for token, i in word_index.items()}\n",
        "\n",
        "# Список с содержимым словаря\n",
        "vocabularyItems = list(word_index.items())\n",
        "\n",
        "# Размер словаря\n",
        "vocabularySize = len(word_index) + 1"
      ],
      "metadata": {
        "id": "EcQSW8aFIlk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Следующий код преобразует обучающие и тестовые вопросы (`questions_train`, `questions_test`) и ответы (`answers_train`, `answers_test`) в последовательности индексов токенов. Используя функцию `texts_to_sequences`, он токенизирует каждый текст с помощью **BPE-токенизатора** (**bpe**) и преобразует токены в индексы из словаря `word_index`:"
      ],
      "metadata": {
        "id": "D8Igzac_IoC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Векторизируем входные и выходные фразы (вопросы и ответы) для train\n",
        "tokenizedQuestions_train = texts_to_sequences(questions_train, bpe, word_index)\n",
        "tokenizedAnswers_train = texts_to_sequences(answers_train, bpe, word_index)\n",
        "\n",
        "# Векторизируем для test\n",
        "tokenizedQuestions_test = texts_to_sequences(questions_test, bpe, word_index)\n",
        "tokenizedAnswers_test = texts_to_sequences(answers_test, bpe, word_index)"
      ],
      "metadata": {
        "id": "l2cKnf3vIoNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Далее подготавливаются токенизированные данные для модели машинного перевода, вычисляя максимальную длину последовательностей, выравнивая их длину нулями, преобразуя в массивы **NumPy** и выводя примеры для отладки. Сначала определяется максимальная длина последовательностей вопросов (`maxLenQuestions`) и ответов (`maxLenAnswers`) на основе обучающих и тестовых данных для согласованности. Затем функция `pad_sequences` выравнивает все последовательности до этих длин, добавляя нули в конец, а данные преобразуются в массивы **NumPy** (`encoderForInput`, `decoderForInput`) для подачи в модель, с выводом примеров вопроса, ответа и их векторизаций для проверки:"
      ],
      "metadata": {
        "id": "o2fun7Y0IpCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем длину самой длинной фразы (на основе всех данных для consistency)\n",
        "maxLenQuestions = max([len(x) for x in tokenizedQuestions_train + tokenizedQuestions_test])\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers_train + tokenizedAnswers_test])\n",
        "\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие фразы (отдельно для вопросов и ответов)\n",
        "paddedQuestions_train = pad_sequences(tokenizedQuestions_train, maxlen=maxLenQuestions, padding='post')\n",
        "paddedAnswers_train = pad_sequences(tokenizedAnswers_train, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "paddedQuestions_test = pad_sequences(tokenizedQuestions_test, maxlen=maxLenQuestions, padding='post')\n",
        "paddedAnswers_test = pad_sequences(tokenizedAnswers_test, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Создаем numpy массив для входа в кодировщик (train)\n",
        "encoderForInput = np.array(paddedQuestions_train)\n",
        "\n",
        "# Создаем numpy массив для входа в декодировщик (train)\n",
        "decoderForInput = np.array(paddedAnswers_train)\n",
        "\n",
        "#  Получим случайный вопрос и ответ\n",
        "random_index = randint(0, len(questions_train)-1)\n",
        "\n",
        "# Выведем фрагмент и размер словаря\n",
        "print( f'Фрагмент словаря : {bpe.vocab[:50]}')\n",
        "print( f'Размер словаря   : {vocabularySize}')\n",
        "\n",
        "# Примеры данных для вопросов\n",
        "print(f'Пример вопроса                         : {questions_train[random_index]}')\n",
        "print(f'Пример векторизации вопроса            : {encoderForInput[random_index]}')\n",
        "print(f'Размер векторизованного вопроса        : {encoderForInput.shape}')\n",
        "print(f'Новая длина вопроса                    : {maxLenQuestions}')\n",
        "\n",
        "# Примеры данных для ответов\n",
        "print(f'Пример ответа                         : {answers_train[random_index]}')\n",
        "print(f'Пример векторизации ответа            : {decoderForInput[random_index]}')\n",
        "print(f'Размер векторизованного ответа        : {decoderForInput.shape}')\n",
        "print(f'Новая длина ответа                    : {maxLenAnswers}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kL-YQOGIpKv",
        "outputId": "0f053dfc-c099-461a-b169-01d29825cb84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фрагмент словаря : ['!', '\"', '#', '$', '%', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '</w>', '<end>', '<start>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V']\n",
            "Размер словаря   : 20001\n",
            "Пример вопроса                         : I'd like to dance.\n",
            "Пример векторизации вопроса            : [1170  303  177 3830    0    0    0    0    0]\n",
            "Размер векторизованного вопроса        : (40000, 9)\n",
            "Новая длина вопроса                    : 9\n",
            "Пример ответа                         : <start> Eu gostaria de dançar. <end>\n",
            "Пример векторизации ответа            : [  27  129 2353  148 3676   26    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "Размер векторизованного ответа        : (40000, 20)\n",
            "Новая длина ответа                    : 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Затем разбиваем текст ответов на последовательности индексов для **train** и избавляемся от тега **SOS**:"
      ],
      "metadata": {
        "id": "DawDAdKEIqfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizedAnswers_train = texts_to_sequences(answers_train, bpe, word_index)\n",
        "\n",
        "for i in range(len(tokenizedAnswers_train)) :\n",
        "    tokenizedAnswers_train[i] = tokenizedAnswers_train[i][1:]"
      ],
      "metadata": {
        "id": "kRFOoVCkIqqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Делаем ответы одной длины и сохраняем в виде массива **Numpy**:"
      ],
      "metadata": {
        "id": "WaAgVBQaIrst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paddedAnswers_train = pad_sequences(tokenizedAnswers_train, maxlen=maxLenAnswers , padding='post')\n",
        "\n",
        "decoderForOutput = np.array(paddedAnswers_train)\n",
        "\n",
        "# Примеры данных для ответов на выходе декодировщика\n",
        "print(f'Пример выходных данных декодировщика                : {answers_train[random_index]}')\n",
        "print(f'Пример векторизации выходных данных декодировщика   : {decoderForOutput[random_index]}')\n",
        "print(f'Размер выходных данных декодировщика                : {decoderForOutput.shape}')\n",
        "print(f'Новая длина выходных данных декодировщика           : {maxLenAnswers}')"
      ],
      "metadata": {
        "id": "7GtEkxmnIr1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57cb05f-e301-4497-9e47-a52c680a89c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример выходных данных декодировщика                : <start> Eu gostaria de dançar. <end>\n",
            "Пример векторизации выходных данных декодировщика   : [ 129 2353  148 3676   26    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0]\n",
            "Размер выходных данных декодировщика                : (40000, 20)\n",
            "Новая длина выходных данных декодировщика           : 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опишем архитектуру кодировщика:"
      ],
      "metadata": {
        "id": "ByOL8JQmIs6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoderInputs = Input(shape=(None , ))                                                    # добавим входной слой\n",
        "encoderEmbedding = Embedding(vocabularySize, LATENT_DIM , mask_zero=True)(encoderInputs)  # добавим эмбеддинг\n",
        "encoderOutputs, state_h , state_c = LSTM(LATENT_DIM, return_state=True)(encoderEmbedding) # добавим LSTM\n",
        "encoderStates = [state_h, state_c]"
      ],
      "metadata": {
        "id": "kADYKy43ItMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опишем архитектуру декодировщика:"
      ],
      "metadata": {
        "id": "8P1S6xnYIuxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoderInputs = Input(shape=(None, ))                                                       # добавим входной слой\n",
        "decoderEmbedding = Embedding(vocabularySize, LATENT_DIM, mask_zero=True) (decoderInputs)    # добавим эмбеддинг\n",
        "decoderLSTM = LSTM(LATENT_DIM, return_state=True, return_sequences=True)                    # добавим LSTM слой\n",
        "decoderOutputs , _ , _ = decoderLSTM(decoderEmbedding, initial_state=encoderStates)         # погоним выход embedding через LSTM (вектора состояний нас уже не интересуют)\n",
        "decoderDense = Dense(vocabularySize, activation='softmax')                                  # создадим dense слой с функцией активации softmax и длиной словаря, созданного токенизатором\n",
        "output = decoderDense (decoderOutputs)"
      ],
      "metadata": {
        "id": "gFTWeVJwIu8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполним сборку модели, её компиляцию и обучение:"
      ],
      "metadata": {
        "id": "FcS78SKVIwC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoderInputs, decoderInputs], output)\n",
        "model.compile(optimizer=RMSprop(), loss='sparse_categorical_crossentropy')\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=BATCH_SIZE, epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1x3TsMUIwMs",
        "outputId": "84afb2f9-8b26-4610-f974-f341c3c92e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 162ms/step - loss: 7.2703\n",
            "Epoch 2/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 165ms/step - loss: 4.6943\n",
            "Epoch 3/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 169ms/step - loss: 4.5096\n",
            "Epoch 4/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 172ms/step - loss: 4.3474\n",
            "Epoch 5/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 170ms/step - loss: 4.1848\n",
            "Epoch 6/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - loss: 4.0222\n",
            "Epoch 7/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - loss: 3.8672\n",
            "Epoch 8/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - loss: 3.7559\n",
            "Epoch 9/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - loss: 3.6353\n",
            "Epoch 10/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - loss: 3.5435\n",
            "Epoch 11/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 171ms/step - loss: 3.4447\n",
            "Epoch 12/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - loss: 3.3505\n",
            "Epoch 13/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 173ms/step - loss: 3.2512\n",
            "Epoch 14/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 170ms/step - loss: 3.1672\n",
            "Epoch 15/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - loss: 3.0882\n",
            "Epoch 16/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 172ms/step - loss: 3.0046\n",
            "Epoch 17/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - loss: 2.9486\n",
            "Epoch 18/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 172ms/step - loss: 2.8747\n",
            "Epoch 19/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - loss: 2.8007\n",
            "Epoch 20/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 172ms/step - loss: 2.7369\n",
            "Epoch 21/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - loss: 2.6843\n",
            "Epoch 22/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 172ms/step - loss: 2.6244\n",
            "Epoch 23/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - loss: 2.5576\n",
            "Epoch 24/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 172ms/step - loss: 2.5084\n",
            "Epoch 25/25\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 172ms/step - loss: 2.4652\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c96e9f7f710>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код создает две отдельные модели для этапа инференса в машинном переводе: модель кодировщика и модель декодировщика. Модель кодировщика (`encoderModel`) принимает закодированные вопросы (`encoderInputs`) и возвращает их контекстные состояния (`state_h`, `state_c`) для передачи в декодировщик. Модель декодировщика (`decoderModel`) принимает входные токены (`decoderInputs`), эмбеддинги (`decoderEmbedding`) и начальные состояния (`decoderStatesInputs`), пропускает их через **LSTM-слой**, обновляет состояния (`state_h`, `state_c`) и предсказывает следующий токен через полносвязный слой с **softmax** (`decoderDense`), возвращая предсказания и новые состояния:"
      ],
      "metadata": {
        "id": "r2pxgEAbIxEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим модель кодировщика\n",
        "# На входе будут закодированные вопросы, на выходе состояния state_h, state_c\n",
        "encoderModel = Model(encoderInputs, encoderStates)\n",
        "\n",
        "# Создадим модель декодировщика\n",
        "decoderStateInput_h = Input(shape=(LATENT_DIM,)) # входной слой для state_h\n",
        "decoderStateInput_c = Input(shape=(LATENT_DIM,)) # входной слой для state_c\n",
        "\n",
        "# Соберем оба входа вместе\n",
        "decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c]\n",
        "\n",
        "# Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs)\n",
        "\n",
        "# LSTM даст нам новые состояния\n",
        "decoderStates = [state_h, state_c]\n",
        "\n",
        "# И ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "decoderOutputs = decoderDense(decoderOutputs)\n",
        "\n",
        "# Определим модель декодировщика\n",
        "decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)"
      ],
      "metadata": {
        "id": "RieJCmAuIxQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот код определяет функцию `predict_translation`, которая выполняет перевод входной фразы (`my_question`) с английского на португальский, используя обученную модель энкодера-декодера. Функция токенизирует входное предложение с помощью **BPE**, преобразует его в последовательность индексов, получает контекстные состояния от энкодера, а затем итеративно генерирует перевод, предсказывая следующий токен через декодер, пока не встретится токен <end> или не превысится максимальная длина ответа, после чего токены объединяются в строку с заменой </w> на пробелы.\n",
        "\n",
        "*Результат* — строка переведенного текста."
      ],
      "metadata": {
        "id": "djc7awpVIy8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для предсказания перевода\n",
        "def predict_translation(my_question):\n",
        "    # Токенизируем предложение\n",
        "    tokens_list = texts_to_sequences([my_question], bpe, word_index)[0]\n",
        "\n",
        "    # Зафиксируем длину последовательности, дополнив нулями\n",
        "    question_token = pad_sequences([tokens_list], maxlen=maxLenQuestions , padding='post')\n",
        "\n",
        "    targetSeq = np.zeros((1, 1))                        # объявляем последовательность\n",
        "    targetSeq[0, 0] = word_index['<start>']     # на начальном этапе последовательность содержит только токен начала последовательности\n",
        "    stop = False                                        # признак окончания генерации последоватнльности токенов\n",
        "    decoded_tokens = []                                 # список с результатами предсказания\n",
        "    statesValues = encoderModel.predict(question_token, verbose=0) # получение контектного вектора из кодировщика\n",
        "\n",
        "    # пока не сработало стоп-условие\n",
        "    while not stop:\n",
        "        # В модель декодера подадим пустую последовательность со словом 'start' и состояния\n",
        "        decOutputs , h , c = decoderModel.predict([targetSeq] + statesValues, verbose=0)\n",
        "        # Получим индекс предсказанного слова.\n",
        "        predictIndex = np.argmax( decOutputs[0, 0, :])\n",
        "\n",
        "        # Создаем переменную для хранения предсказанного слова\n",
        "        predictWord = index_to_word.get(predictIndex, None)\n",
        "        if predictWord is None:\n",
        "            stop = True\n",
        "            continue\n",
        "\n",
        "        # Добавляем к списку\n",
        "        decoded_tokens.append(predictWord)\n",
        "\n",
        "        # Если найденное слово является признаком окончания генерации '<end>' или ответ превышает максимальную длину ответа, то останавливаем генерацию\n",
        "        if predictWord == '<end>' or len(decoded_tokens) > maxLenAnswers:\n",
        "            stop = True # устанавливаем признак окончания генерации\n",
        "\n",
        "        # Обновляем входной токен для следующего шага генерации\n",
        "        targetSeq = np.zeros((1, 1))\n",
        "        targetSeq[0, 0] = predictIndex\n",
        "\n",
        "        # Обновляем состояния ячейки и переходим к следующему шагу цикла\n",
        "        statesValues = [h, c]\n",
        "\n",
        "    # Детокенизируем\n",
        "    decoded_answer = ''.join(decoded_tokens).replace('</w>', ' ').replace('<end>', '').strip()\n",
        "\n",
        "    return decoded_answer"
      ],
      "metadata": {
        "id": "ZhVzxeSlIzHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Финальный код демонстрирует работу модели перевода на **10** случайных примерах из тестовой выборки. Он выбирает **10** случайных индексов из `questions_test`, для каждого индекса получает английскую фразу, истинный португальский перевод (очищенный от токенов <start> и <end>), и предсказанный перевод с помощью функции `predict_translation`, затем сохраняет их в списки и создает таблицу `results_df` с колонками \"**Английская фраза**\", \"**Португальский перевод**\" и \"**Предсказанный перевод**\" для вывода результатов:"
      ],
      "metadata": {
        "id": "vRlEiJhyQB96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Демонстрация на 10 примерах из тестовой выборки\n",
        "num_examples = 10\n",
        "test_indices = np.random.choice(len(questions_test), num_examples, replace=False)\n",
        "\n",
        "eng_phrases = []\n",
        "true_por = []\n",
        "pred_por = []\n",
        "\n",
        "for idx in test_indices:\n",
        "    eng = questions_test[idx]\n",
        "    true = answers_test[idx].replace(SOS + ' ', '').replace(' ' + EOS, '').strip()\n",
        "    pred = predict_translation(eng)\n",
        "\n",
        "    eng_phrases.append(eng)\n",
        "    true_por.append(true)\n",
        "    pred_por.append(pred)\n",
        "\n",
        "# Сформируем таблицу\n",
        "results_df = pd.DataFrame({\n",
        "    'Английская фраза': eng_phrases,\n",
        "    'Португальский перевод': true_por,\n",
        "    'Предсказанный перевод': pred_por\n",
        "})\n",
        "\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "cqQjCt-uQCKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4dfa5bd-7264-4279-e120-37c906220865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Английская фраза     Португальский перевод    Предсказанный перевод\n",
            "0      Tom was very sad.  Tom estava muito triste.  Tom estava muito feliz.\n",
            "1    I want this guitar.     Eu quero este violão.  Eu quero mais de volta.\n",
            "2   It finally happened.     Finalmente aconteceu.           Isso foi isso.\n",
            "3            He gave up.             Ele desistiu.         Ele me foi tudo.\n",
            "4   I hurt myself today.        Me machuquei hoje.         Eu me sinto bem.\n",
            "5  Tom was never caught.       Tom nunca foi pego.     Tom estava com fome.\n",
            "6   This site is useful.         Este site é útil.            Esta é a meu.\n",
            "7        I'm quite sure.      Tenho quase certeza.   Estou cansado de novo.\n",
            "8     Let's have dinner.             Vamos jantar.        Vamos nos ajudar.\n",
            "9       I made that one.            Eu fiz aquele.    Eu me vou fazer isso.\n"
          ]
        }
      ]
    }
  ]
}